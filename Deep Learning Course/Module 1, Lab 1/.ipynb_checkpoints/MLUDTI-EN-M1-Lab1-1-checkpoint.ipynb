{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<center><img src=\"images/logo.png\" alt=\"AWS Logo\" width=\"400\" style=\"background-color:white; padding:1em;\" /></center> <br/>\n",
        "\n",
        "# Application of Deep Learning to Text and Image Data\n",
        "## Module 1, Lab 1, Notebook 1: Getting Started with PyTorch\n",
        "\n",
        "This notebook will introduce you to the PyTorch deep learning framework, which is the tool that you will use throughout this course to implement neural network models. For more information, see the [PyTorch documentation](https://pytorch.org/docs/stable/index.html).\n",
        "\n",
        "This notebook has been divided into two parts. In the first part of the notebook, you will learn how to use PyTorch to manipulate data to be ready for use in model training. In the second part, you will practice a crucial step in nearly all deep learning optimization algorithms: _differentiation_.\n",
        "\n",
        "To learn these topics, you will examine how PyTorch stores and manipulates data in *n*-dimensional arrays, which are also called _tensors_. To define the tensors and arrays, you will use _NumPy_, which is the most widely used scientific computing package in Python.\n",
        "\n",
        "Other frameworks are available, but this lab focuses on PyTorch, which has two key features. First, GPU is well-supported to accelerate the computation, whereas NumPy supports only CPU computation. Second, the tensor class supports automatic differentiation. These properties make the tensor class suitable for deep learning.\n",
        "\n",
        "You will learn the following:\n",
        "\n",
        "- How to explore tensors\n",
        "- Why you index and slice tensors\n",
        "- How to index and slice tensors\n",
        "- Common tensor operations \n",
        "- How to perform tensor operations on data\n",
        "- How to convert tensors to other Python objects\n",
        "\n",
        "---\n",
        "\n",
        "You will be presented with activities throughout the notebook: <br/>\n",
        "\n",
        "|<img style=\"float: center;\" src=\"images/activity.png\" alt=\"Activity\" width=\"125\"/>| \n",
        "| --- | \n",
        "|<p style=\"text-align:center;\"> No coding is needed for an activity. You try to understand a concept, <br/>answer questions, or run a code cell.</p>|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Index\n",
        "\n",
        "- [Data Manipulation](#Data-Manipulation)\n",
        "  - [Exploring Tensors](#Exploring-Tensors)\n",
        "  - [Indexing and Slicing Tensors](#Indexing-and-Slicing-Tensors)\n",
        "  - [Tensor Operations](#Tensor-Operations)\n",
        "  - [Conversion to Other Python Objects](#Conversion-to-Other-Python-Objects)\n",
        "- [Automatic Differentiation](#Automatic-Differentiation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data manipulation\n",
        "In this section, you will practice basic data manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install libraries\n",
        "!pip install -U -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import basic libraries to work with data and tensors\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Import utility functions for activities\n",
        "from MLUDTI_EN_M1_Lab1_quiz_questions import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exploring tensors\n",
        "\n",
        "A tensor represents an array of numerical values. A one-axis tensor corresponds to a one-dimensional vector in math, and a two-axis tensor corresponds to a matrix. Tensors with more than two axes don't have special mathematical names.\n",
        "\n",
        "You can use the `arange` operation to create a row vector $x$ that contains the first 12 integers, starting with 0. Unless otherwise specified, a new tensor will be stored in main memory and designated for CPU-based computation.\n",
        "\n",
        "__Note:__ Integers are created as floats by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create a tensor with values in the range 0–11\n",
        "x = torch.arange(12)\n",
        "\n",
        "# Print the tensor\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can view a tensor's shape (the length along each axis) by reviewing its `shape` property."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check for tensor size\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can use the `reshape` function to transform the tensor $x$ from a row vector with shape (12) to a matrix with shape (3, 4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Reshape the tensor into a matrix with three rows and four columns\n",
        "x_reshaped = x.reshape(3, 4)\n",
        "\n",
        "# Print the reshaped tensor\n",
        "x_reshaped\n",
        "x.reshape(3, 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also reshape a tensor into a matrix by choosing one dimension and letting the other dimension be calculated implicitly (automatically). This is done by using -1 for the dimension that you want to be determined automatically.\n",
        "\n",
        "For example, instead of calling `x.reshape(3,4)`, you can call either `x.reshape(-1,4)` or `x.reshape(3,-1)` to get the same result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It's important to initialize a tensor in memory with the desired shape. You can do this by initializing with zeros, ones, other constants, or numbers that are randomly sampled from a specific distribution.\n",
        "\n",
        "You can use the `zeros()` function to create a tensor with all elements set to 0 and a shape of (2, 3, 4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create two matrices with three rows and four columns respectively and fill with 0s\n",
        "zeros_tensor = torch.zeros((2, 3, 4))\n",
        "\n",
        "# Print the matrices\n",
        "zeros_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, you can use the `ones()` function to create tensors where each element is set to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create two matrices with three rows and four columns respectively and fill with 1s\n",
        "ones_tensor = torch.ones((2, 3, 4))\n",
        "\n",
        "# Print the matrices\n",
        "ones_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In other situations, you will want to create a tensor with randomly sampled values from a probability distribution.\n",
        "\n",
        "For example, when you construct arrays to serve as parameters in a neural network, you typically initialize their values randomly. To do this, you can use the `randn()` function to create a tensor where each of its elements is randomly sampled from a standard Gaussian (normal) distribution with a mean of 0 and a standard deviation of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create a 3x4 matrix where the fill values are randomly sampled from a normal distribution\n",
        "x = torch.randn(3, 4)\n",
        "\n",
        "# Print the matrix\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you work with tensors, you will need to be able to verify that they have the expected shape, size, and type of stored values:\n",
        "- Use the `shape` attribute to determine the shape of the tensor.\n",
        "- Use the `numel()` function to determine the number of elements in the tensor. This is equal to the product of the components of the shape.\n",
        "- Use the `.dtype` attribute to determine the data type of the stored values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check shape (rows and columns), total number of elements, and what data type is stored in the tensor\n",
        "x.shape, x.numel(), x.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
        "    <h3><i>Try it yourself!</i></h3>\n",
        "    <br>\n",
        "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
        "    <p style=\" text-align: center; margin: auto;\">To test your understanding of basic tensor functionality, run the following cell.</p>\n",
        "    <br>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Run this cell to display the question and check your answer\n",
        "question_1\n",
        "\n",
        "# For help, read the section \"Exploring Tensors\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Indexing and slicing tensors\n",
        "\n",
        "You can access elements in a tensor by index the same way that you would access elements in a Python array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create a 3x4 matrix where the fill values are randomly sampled from a normal distribution\n",
        "x = torch.randn(3, 4)\n",
        "\n",
        "# Print the full tensor, the last row, and the last two rows\n",
        "x, x[-1], x[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can access values for a specific location by specifying all of the location indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "x[0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also write elements of a matrix by specifying indices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Assign a specific value in a given row and column\n",
        "x[1, 2] = 9\n",
        "\n",
        "# Print the tensor with the newly assigned value\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also use multidimensional slicing to replace numbers inside the tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Assign the same value to a slice of rows and columns\n",
        "x[0:2, :] = 12\n",
        "\n",
        "# Print the tensor with the newly assigned values\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
        "    <h3><i>Try it yourself!</i></h3>\n",
        "    <br>\n",
        "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
        "    <p style=\" text-align: center; margin: auto;\">To test your understanding of indexing and slicing tensors, run the following cell.</p>\n",
        "    <br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Run this cell to display the question and check your answer\n",
        "question_2\n",
        "\n",
        "# x[0] would return the first row, not the very first element.\n",
        "# x[1] would return the second row. Keep in mind, indexing starts with 0 in Python.\n",
        "# For help, read the section \"Indexing and Slicing Tensors\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor operations\n",
        "\n",
        "You can use common arithmetic operators (`+`, `-`, `*`, `/`, and `**`) for element-wise operations on any identically shaped tensors of arbitrary shape.\n",
        "\n",
        "In the following example, a five-element tuple is created where each element is the result of an element-wise operation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create two tensors: x and y filled with some values\n",
        "x = torch.tensor([1.0, 2.0, 4.0, 8.0])\n",
        "y = torch.tensor([2.0, 2.0, 2.0, 2.0])\n",
        "\n",
        "# Sum, difference, element-wise multiplication, division, exponentiation (operator **)\n",
        "x + y, x - y, x * y, x / y, x**y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can apply many more element-wise operations, including unary operators such as exponentiation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calculate the exponential for each element in the tensor\n",
        "torch.exp(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In addition to element-wise computations, you can calculate linear algebra operations including vector dot products and matrix multiplication. \n",
        "\n",
        "The dot product is an important concept in ML because it can be used to quantify similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calculate the dot product between two tensors\n",
        "torch.dot(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can also calculate the dot product of two vectors manually by performing an element-wise multiplication and then summing the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calculate the dot product and sum for two tensors\n",
        "torch.sum(x * y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To perform matrix multiplication of tensors, PyTorch offers the `matmul()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Product of a 3x4 matrix and 4x1 vector\n",
        "A = torch.arange(12, dtype=torch.float).reshape(3, 4)\n",
        "print(A)\n",
        "\n",
        "x = torch.arange(4, dtype=torch.float)\n",
        "print(x)\n",
        "\n",
        "# Perform the matrix multiplication\n",
        "torch.matmul(A, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# The matmul can be calculated several ways\n",
        "A.matmul(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that matrix multiplication is not communicative. If you have matrices that aren't shaped properly for multiplication, you will receive a runtime error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Uncomment and run the following cell. You will get a runtime error.\n",
        "\n",
        "# torch.matmul(x, A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch helps you do complex operations. You can create tensors, reshape them, and then multiply them to get the result with a few lines of code. These operations will make it easier for you to train and validate a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Initialize matrix A\n",
        "A = torch.arange(12).reshape(6, 2)\n",
        "\n",
        "# Initialize matrix B\n",
        "B = torch.arange(10).reshape(2, 5)\n",
        "\n",
        "# Calculate the matrix multipliation between A and B and the resulting shape\n",
        "C = torch.matmul(A, B)\n",
        "print(C)\n",
        "print(C.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For more information about linear algebra operations, see [Linear Algebra](http://d2l.ai/chapter_preliminaries/linear-algebra.html) on the Dive into Deep Learning site.\n",
        "\n",
        "For more information about the PyTorch `matmul`, `dot`, and `mm` operations, see the PyTorch documentation: [matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html), [dot](https://pytorch.org/docs/stable/generated/torch.dot.html), and [mm](https://pytorch.org/docs/stable/generated/torch.mm.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 4px solid coral; text-align: center; margin: auto;\">\n",
        "    <h3><i>Try it yourself!</i></h3>\n",
        "    <br>\n",
        "    <p style=\"text-align:center;margin:auto;\"><img src=\"images/activity.png\" alt=\"Activity\" width=\"100\" /> </p>\n",
        "    <p style=\" text-align: center; margin: auto;\">To test your understanding of tensor operations, run the following cell.</p>\n",
        "    <br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Run this cell to display the question and check your answer\n",
        "question_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Conversion to other Python objects\n",
        "\n",
        "It's important to be able to convert between PyTorch and NumPy tensors. When you convert between different types, they don't share memory. This means that you need more memory resources; however, computations are not halted when different computations need to be performed on the CPU compared to the GPU. Because they don't share memory, no wait time occurs while deciding whether the NumPy package or PyTorch needs to perform an operation because they aren't using the same chunk of memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create a NumPy tensor\n",
        "A = x.numpy()\n",
        "\n",
        "# Convert the NumPy tensor to a PyTorch tensor\n",
        "B = torch.tensor(A)\n",
        "\n",
        "# Print the resulting types\n",
        "type(A), type(B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To convert a size-1 tensor to a Python scalar, you can use the `item` function or one of  Python's built-in functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([3.5])\n",
        "\n",
        "a, a.item(), float(a), int(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Automatic differentiation\n",
        "\n",
        "In this section, you will practice automatic differentiation and see how to use PyTorch to take advantage of GPUs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can train a deep learning model on a CPU or GPU. The most computationally demanding piece in a neural network is multiple matrix multiplications. In general, when training on a CPU, each operation will be done sequentially. When using a GPU, all the operations will be done in parallel, which makes GPU faster than CPU.\n",
        "\n",
        "CUDA is a parallel computing platform that focuses on general computing on GPUs. PyTorch natively supports CUDA, and you can access it with the `torch.cuda` library. To find out whether you have a GPU at your disposal and set your device accordingly, you can use `cuda.is_available()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Set to GPU if GPU is available; otherwise, use CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Print device type for reference\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PyTorch can allocate the tensors to the GPU on object creation by specifying the `device` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Create a tensor and allocate memory with 'requires_grad', store on GPU\n",
        "a = torch.arange(4, requires_grad=True, dtype=torch.float, device=device)\n",
        "a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Differentiation is a crucial step in nearly all deep learning optimization algorithms. In this section, you will examine how PyTorch’s automatic differentiation expedites this work by automatically calculating derivatives, which enables the system to backpropagate gradients.\n",
        "\n",
        "Consider an example where you want to differentiate a function $f(\\mathbf{x}) = 0.6x^2$ with respect to parameter $x$. Start by assigning an initial value of $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Print tensor that was created in the previous section\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Before you calculate the gradient of $f(x)$ with respect to $x$, you need a place to store it.\n",
        "\n",
        "It's important not to allocate new memory every time you take a derivative with respect to a parameter because the same parameters might be updated thousands or millions of times. This will cause memory to run out.\n",
        "\n",
        "__Note__: A gradient of a scalar-valued function with respect to a vector $x$ is itself vector valued and has the same shape as $x$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Allocate memory for a tensor's gradient by invoking .requires_grad\n",
        "# Note that the tensor can be created already with an attached gradient by writing x = torch.tensor([1., 2., 4., 8.], requires_grad=True)\n",
        "x.requires_grad_(True)\n",
        "\n",
        "# After calculating the gradient taken with respect to x, you can access it by using the grad attribute\n",
        "# The grad attribute's values are initialized with None\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, calculate $f(x)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calculate the dot product and multiply with .6 (as in the toy function example)\n",
        "y = 0.6 * torch.dot(x, x)\n",
        "\n",
        "# Print new tensor\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, you can automatically calculate the gradient of $f(x)$ with respect to each component of $x$ by calling the function for backpropagation and printing the gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calculate the gradient\n",
        "y.backward()\n",
        "\n",
        "# Print the gradient values\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, determine if this is the expected output. The gradient of the function $f(x) = 0.6x^2$ with respect to $x$ should be $1.2x$.\n",
        "\n",
        "Verify that the desired gradient was calculated correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Check if the calculated gradient matches the manual calculation\n",
        "x.grad == 1.2 * x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "## Conclusion\n",
        "\n",
        "In this notebook, you practiced using PyTorch to perform different mathematical calculations.\n",
        "\n",
        "--- \n",
        "## Next lab\n",
        "In the next lab, you will learn the basics of neural networks and train your first one."
      ]
    }
  ],
  "metadata": {
    "instance_type": "ml.t3.medium",
    "kernelspec": {
      "display_name": "conda_pytorch_p310",
      "language": "python",
      "name": "conda_pytorch_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
